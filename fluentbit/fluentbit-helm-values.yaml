# Original version from
# https://github.com/fluent/helm-charts/blob/main/charts/fluent-bit/values.yaml

# Default values for fluent-bit.

# Could be DaemonSet or Deployment, but for our case, DaemonSet is
# better fit to collect logs from all containers. Deployment may be
# required in a large scale production deployment, for Fluent-bit
# cascading.
#
# TODO: Should we use fluentd or fluent-bit for cascading?
kind: DaemonSet

# We can't access https://cr.fluentbit.io/fluent/fluent-bit. The tag
# value is from DockerHub.
image:
  repository: cr.fluentbit.io/fluent/fluent-bit
  tag: "1.9.10"
  pullPolicy: IfNotPresent

testFramework:
  enabled: true
  image:
    repository: busybox
    pullPolicy: Always
    tag: latest

# In case special permission is needed, or we just use default values.
serviceAccount:
  create: true
  annotations: {}
  name:

rbac:
  create: true
  nodeAccess: false

podSecurityPolicy:
  create: false
  annotations: {}

openShift:
  enabled: false

# Fluent-bit itself also exports Prometheus counter to allow SREs
# analyze log ingestion speed. Make sure it's enabled.
service:
  type: ClusterIP
  port: 2020
  loadBalancerClass:
  loadBalancerSourceRanges: []
  labels: {}
  annotations:
   prometheus.io/path: "/api/v1/metrics/prometheus"
   prometheus.io/port: "2020"
   prometheus.io/scrape: "true"

# TODO: Should it be enabled?
serviceMonitor:
  enabled: false

prometheusRule:
  enabled: false

# This setting enables a private fluent-bit Grafana installation. It's
# not needed since we always have a separated Grafana.
dashboards:
  enabled: false

lifecycle: {}
  # preStop:
  #   exec:
  #     command: ["/bin/sh", "-c", "sleep 20"]

livenessProbe:
  httpGet:
    path: /
    port: http

readinessProbe:
  httpGet:
    path: /api/v1/health
    port: http

resources:
   limits:
     cpu: 100m
     memory: 128Mi
   requests:
     cpu: 100m
     memory: 128Mi

## only available if kind is Deployment
ingress:
  enabled: false

## only available if kind is Deployment
autoscaling:
  enabled: false

## only available if kind is Deployment
podDisruptionBudget:
  enabled: false

flush: 1

metricsPort: 2020

extraPorts: []
#   - port: 5170
#     containerPort: 5170
#     protocol: TCP
#     name: tcp
#     nodePort: 30517

extraVolumes: []

extraVolumeMounts: []

updateStrategy: {}

# Make use of a pre-defined configmap instead of the one templated here
existingConfigMap: ""

networkPolicy:
  enabled: false

luaScripts: {}

## https://docs.fluentbit.io/manual/administration/configuring-fluent-bit/classic-mode/configuration-file
config:
  service: |
    [SERVICE]
        Daemon Off
        Flush {{ .Values.flush }}
        Log_Level {{ .Values.logLevel }}
        Parsers_File parsers.conf
        Parsers_File custom_parsers.conf
        HTTP_Server On
        HTTP_Listen 0.0.0.0
        HTTP_Port {{ .Values.metricsPort }}
        Health_Check On

  ## https://docs.fluentbit.io/manual/pipeline/inputs
  ## In our K3S installation, we intentionally parse different log
  ## formats by matching different log types.
  ## 
  ## Known issue: A long tag name like grafana or prometheus can cause
  ## losing tag. I haven't spotted the root cause. Need further
  ## diagnose. For now, just keep tag on <= 4 characters.
  inputs: |
    [INPUT]
        Name tail
        Path /var/log/containers/*kube-system*.log
        multiline.parser docker, cri
        Tag kube.*
        Mem_Buf_Limit 5MB
        Skip_Long_Lines On
    [INPUT]
        Name tail
        Path /var/log/containers/prometheus*.log
        multiline.parser docker, cri
        Tag prom.*
        Mem_Buf_Limit 5MB
        Skip_Long_Lines On
    [INPUT]
        Name tail
        Path /var/log/containers/loki*.log
        multiline.parser docker, cri
        Tag loki.*
        Mem_Buf_Limit 5MB
        Skip_Long_Lines On
    [INPUT]
        Name tail
        Path /var/log/containers/minio*.log
        multiline.parser docker, cri
        Tag mini.*
        Mem_Buf_Limit 5MB
        Skip_Long_Lines On
    [INPUT]
        Name tail
        Path /var/log/containers/grafana*.log
        multiline.parser docker, cri
        Tag graf.*
        Mem_Buf_Limit 5MB
        Skip_Long_Lines On
    [INPUT]
        Name tail
        Path /var/log/containers/fluent*.log
        multiline.parser docker, cri
        Tag flue.*
        Mem_Buf_Limit 5MB
        Skip_Long_Lines On

  ## https://docs.fluentbit.io/manual/pipeline/filters
  ## Set Merge_Log to off, since there's no core K8S logs is in JSON
  ## format. Just skip trying for a better performance.
  ##
  ## We use two filters - one to get K8S info (added as 2nd level JSON),
  ## then lift to top level so it can be indexed when writing to Loki
  ## by Line_Format.
  ##
  ## NOTE: kubernetes filter requires incoming tags longer than
  ## Kube_Tag_Prefix (default value: kube.var.log.containers.), or it
  ## skips processing. So make sure we always use .* suffix in tag to
  ## form an acceptable tag.
  ##
  ## NOTE: Reserve_Data is required or Parser filter removes all
  ## kubernetes fields. To me it's a bad design in fluent-bit, yet
  ## somehow please understand.
  filters: |
    [FILTER]
        Name kubernetes
        Match *
        Merge_Log Off
        Keep_Log Off
        K8S-Logging.Parser On
        K8S-Logging.Exclude On
        Labels On
        Annotations On
    [FILTER]
        Name nest
        Match *
        Operation lift
        Nested_Under kubernetes
    [FILTER]
        Name nest
        Match *
        Operation lift
        Nested_Under labels
    [Filter]
        Name parser
        Match prom.*
        Parser logfmt
        Key_Name log
        Preserve_Key false
        Reserve_Data true
    [Filter]
        Name parser
        Match graf.*
        Parser logfmt
        Key_Name log
        Preserve_Key false
        Reserve_Data true

  ## https://docs.fluentbit.io/manual/pipeline/outputs/loki 
  ## auto_kubernetes_labels adds "k8s_app" and "pod_template_hash" tags.
  ## Line_Format must set to 'json', as it impacts "kubernetes" tag
  ## inserted by kubernetes filter.
  ##
  ## Auto_Kubernetes_Label does not take effect anymore when two nest
  ## filters are added. It appears it actually extracts values from
  ## kubernetes.labels field. The two nest filters above lift the
  ## values to top-level, which causes Auto_Kubernetes_Labels fails to
  ## find data, and does nothing instead.
  outputs: |
    [OUTPUT]
        Name loki
        Match kube.*
        Host loki-gateway.loki.svc.cluster.local
        Port 80
        Line_Format json
        Retry_Limit False
        Labels job=fluentbit,svc=kube
        Auto_Kubernetes_Labels On
    [OUTPUT]
        Name loki
        Match prom.*
        Host loki-gateway.loki.svc.cluster.local
        Port 80
        Line_Format json
        Retry_Limit False
        Labels job=fluentbit,svc=prometheus
        Auto_Kubernetes_Labels On
    [OUTPUT]
        Name loki
        Match loki.*
        Host loki-gateway.loki.svc.cluster.local
        Port 80
        Line_Format json
        Retry_Limit False
        Labels job=fluentbit,svc=loki
        Auto_Kubernetes_Labels On
    [OUTPUT]
        Name loki
        Match mini.*
        Host loki-gateway.loki.svc.cluster.local
        Port 80
        Line_Format json
        Retry_Limit False
        Labels job=fluentbit,svc=minio
        Auto_Kubernetes_Labels On
    [OUTPUT]
        Name loki
        Match graf.*
        Host loki-gateway.loki.svc.cluster.local
        Port 80
        Line_Format json
        Retry_Limit False
        Labels job=fluentbit,svc=grafana
        Auto_Kubernetes_Labels On
    [OUTPUT]
        Name loki
        Match flue.*
        Host loki-gateway.loki.svc.cluster.local
        Port 80
        Line_Format json
        Retry_Limit False
        Labels job=fluentbit,svc=fluentbit
        Auto_Kubernetes_Labels On

  ## https://docs.fluentbit.io/manual/administration/configuring-fluent-bit/classic-mode/upstream-servers
  ## This configuration is deprecated, please use `extraFiles` instead.
  upstream: {}

  ## https://docs.fluentbit.io/manual/pipeline/parsers
  ## No use for now. Grafana stack does not use JSON format.
  customParsers: |
    [PARSER]
        Name docker_no_time
        Format json
        Time_Keep Off
        Time_Key time
        Time_Format %Y-%m-%dT%H:%M:%S.%L
    [PARSER]
        Name logfmt
        Format logfmt

  # This allows adding more files with arbitary filenames to
  # /fluent-bit/etc by providing key/value pairs.
  # The key becomes the filename, the value becomes the file content.
  extraFiles: {}

# The config volume is mounted by default,
# either to the existingConfigMap value, or the default of "fluent-bit.fullname"
volumeMounts:
  - name: config
    mountPath: /fluent-bit/etc/fluent-bit.conf
    subPath: fluent-bit.conf
  - name: config
    mountPath: /fluent-bit/etc/custom_parsers.conf
    subPath: custom_parsers.conf

daemonSetVolumes:
  - name: varlog
    hostPath:
      path: /var/log
  - name: varlibdockercontainers
    hostPath:
      path: /var/lib/docker/containers
  - name: etcmachineid
    hostPath:
      path: /etc/machine-id
      type: File

daemonSetVolumeMounts:
  - name: varlog
    mountPath: /var/log
  - name: varlibdockercontainers
    mountPath: /var/lib/docker/containers
    readOnly: true
  - name: etcmachineid
    mountPath: /etc/machine-id
    readOnly: true

args: []

command: []

# This supports either a structured array or a templatable string
initContainers: []

logLevel: info 
